{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6695a872",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a937e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas \n",
    "import open_clip\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as Func\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from tqdm import tqdm\n",
    "import copy \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b535c",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b58c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k') # pretrained on pretrained on LAION-2B\n",
    "                                                                                                         # preprocess: this is the image processing pipeline\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "model = model.to(device=device).eval() # we put it on eval mode as we want to investigate zero-shot mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26913428",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fed69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = random_split(CIFAR10(root='./data', train=True, download=True, transform=preprocess), [45000, 5000])\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=preprocess)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,   batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset,  batch_size=256, shuffle=False, num_workers=4)\n",
    "class_names = test_dataset.classes  # CIFAR-10 names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643e31f",
   "metadata": {},
   "source": [
    "### Zero-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33fb682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy: 0.9362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_text_embeddings(classnames, templates):\n",
    "    texts = []\n",
    "    for t in templates:\n",
    "        for c in classnames:\n",
    "            # texts.append(t.format(classname=c))\n",
    "            texts.append(t.format(c) if \"{}\" in t else t.format(classname=c))\n",
    "    tokens = tokenizer(texts).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_emb = model.encode_text(tokens) # currently, its shape is: (#templates * #classes, Embedding_shape)\n",
    "    # average across templates per class\n",
    "    Embedding_shape = text_emb.shape[-1]\n",
    "    text_emb = text_emb.reshape(len(templates), len(classnames), Embedding_shape).mean(dim=0) # (#templates * #classes, Embedding_shape) -> \n",
    "                                                                                              # (#templates, #classes, Embedding_shape) -> (#classes, Embedding_shape)\n",
    "    text_emb = Func.normalize(text_emb, dim=-1) # we normalize our embeddings \n",
    "    return text_emb\n",
    "\n",
    "# templates (it's adjustable)\n",
    "templates = [\n",
    "    \"a photo of a {classname}.\",\n",
    "    \"this is a {classname}.\", \n",
    "    \"this image is {classname}\"\n",
    "]\n",
    "text_emb = compute_text_embeddings(class_names, templates)\n",
    "\n",
    "# classify our test images\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        image_emb = model.encode_image(imgs)\n",
    "        image_emb = Func.normalize(image_emb, dim=-1)\n",
    "        logits = image_emb @ text_emb.T  # cosine similarity\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        correct += (preds == labels.numpy()).sum()\n",
    "        total += labels.size(0)\n",
    "print(\"Zero-shot accuracy:\", correct/total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119bcec",
   "metadata": {},
   "source": [
    "### Inference just based on obtained features from images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff791674",
   "metadata": {},
   "source": [
    "#### 1. By Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb1a8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear probe (logreg) accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "def img_feature_extractor(loader):\n",
    "    feats = [] # contains model-generated features for each batch\n",
    "    labs  = [] # contains labels for each batch\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feature = model.encode_image(imgs)\n",
    "            feature = feature.cpu().numpy()\n",
    "            feats.append(feature)\n",
    "            labs.append(labels.numpy())\n",
    "    feats = np.concatenate(feats, axis=0)\n",
    "    labs  = np.concatenate(labs, axis=0)\n",
    "    return feats, labs\n",
    "\n",
    "train_features, train_labels = img_feature_extractor(train_loader)\n",
    "val_features, val_labels = img_feature_extractor(val_loader)\n",
    "test_features, test_labels = img_feature_extractor(test_loader)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, C=1.0)\n",
    "clf.fit(train_features, train_labels)\n",
    "acc = clf.score(test_features, test_labels)\n",
    "print(\"Linear probe (logreg) accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642858b9",
   "metadata": {},
   "source": [
    "#### 1. By an MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdf2c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Validation Accuracy: 0.9594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Validation Accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Validation Accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Validation Accuracy: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Validation Accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Validation Accuracy: 0.9668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Validation Accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Validation Accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Validation Accuracy: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Validation Accuracy: 0.9654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Validation Accuracy: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Validation Accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Validation Accuracy: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Validation Accuracy: 0.9654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Validation Accuracy: 0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Validation Accuracy: 0.9654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Validation Accuracy: 0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Validation Accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Validation Accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Validation Accuracy: 0.9662\n",
      "Loaded best model (Val Acc = 0.9680)\n",
      "Final Test Accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "# Convert features and labels to tensors``\n",
    "train_feats_tensor = torch.tensor(train_features, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "val_feats_tensor = torch.tensor(val_features, dtype=torch.float32)\n",
    "val_labels_tensor = torch.tensor(val_labels, dtype=torch.long)\n",
    "test_feats_tensor  = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_labels_tensor  = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(train_feats_tensor, train_labels_tensor)\n",
    "val_dataset   = TensorDataset(val_feats_tensor, val_labels_tensor)\n",
    "test_dataset  = TensorDataset(test_feats_tensor, test_labels_tensor)\n",
    "\n",
    "train_loader_mlp = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader_mlp   = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader_mlp  = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Define MLP \n",
    "num_features = train_features.shape[1]\n",
    "num_classes  = len(np.unique(train_labels))\n",
    "MLP_probe = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        ).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(MLP_probe.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "NUM_EPOCHS = 20\n",
    "best_val_acc = 0.0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    MLP_probe.train()\n",
    "    batch_bar = tqdm(train_loader_mlp, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [train]\", leave=False)\n",
    "\n",
    "    for x_batch, y_batch in batch_bar:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = MLP_probe(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    # Validation\n",
    "    MLP_probe.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader_mlp:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = MLP_probe(x_batch)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state_dict = MLP_probe.state_dict()\n",
    "\n",
    "# Load the best model\n",
    "MLP_probe.load_state_dict(best_state_dict)\n",
    "print(f\"Loaded best model (Val Acc = {best_val_acc:.4f})\")\n",
    "\n",
    "# Final Test Evaluation\n",
    "MLP_probe.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader_mlp:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        logits = MLP_probe(x_batch)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "test_acc = correct / total\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6347a",
   "metadata": {},
   "source": [
    "### Inference based on obtained features from both images and texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=510.3517\n",
      "Epoch 2, loss=494.9237\n",
      "Epoch 3, loss=493.2440\n",
      "Accuracy after training MLP heads: 0.9674\n"
     ]
    }
   ],
   "source": [
    "class ProjectionMLP(nn.Module):\n",
    "    def __init__(self, input_dim=512, hidden=512, output_dim=512):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# freeze CLIP model \n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "img_head = ProjectionMLP(input_dim=512).to(device)\n",
    "txt_head = ProjectionMLP(input_dim=512).to(device)\n",
    "optimizer = torch.optim.Adam(list(img_head.parameters()) + list(txt_head.parameters()), lr=1e-3)\n",
    "templates = [\"a photo of a {}.\", \"a cropped photo of a {}.\"]\n",
    "text_embeddings = compute_text_embeddings(class_names, templates).to(device)\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "best_val_acc = 0.0\n",
    "best_img_head_state = None\n",
    "best_txt_head_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    # training loop\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            img_emb = model.encode_image(imgs)\n",
    "            img_emb = Func.normalize(img_emb, dim=-1)\n",
    "\n",
    "        # pass through MLP heads\n",
    "        img_proj = img_head(img_emb)\n",
    "        txt_proj = txt_head(text_embeddings)\n",
    "        img_proj = Func.normalize(img_proj, dim=-1)\n",
    "        txt_proj = Func.normalize(txt_proj, dim=-1)\n",
    "\n",
    "        logits = img_proj @ txt_proj.T\n",
    "        loss = Func.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, loss={total_loss:.4f}\")\n",
    "\n",
    "    # validation evaluation\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        txt_proj = txt_head(text_embeddings)\n",
    "        txt_proj = Func.normalize(txt_proj, dim=-1)\n",
    "\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            img_emb = model.encode_image(imgs)\n",
    "            img_emb = Func.normalize(img_emb, dim=-1)\n",
    "\n",
    "            img_proj = img_head(img_emb)\n",
    "            img_proj = Func.normalize(img_proj, dim=-1)\n",
    "\n",
    "            logits = img_proj @ txt_proj.T\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_img_head_state = copy.deepcopy(img_head.state_dict())\n",
    "        best_txt_head_state = copy.deepcopy(txt_head.state_dict())\n",
    "\n",
    "# load best model for testing \n",
    "img_head.load_state_dict(best_img_head_state)\n",
    "txt_head.load_state_dict(best_txt_head_state)\n",
    "\n",
    "# test evaluation \n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    txt_proj = txt_head(text_embeddings)\n",
    "    txt_proj = Func.normalize(txt_proj, dim=-1)\n",
    "\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        img_emb = model.encode_image(imgs)\n",
    "        img_emb = Func.normalize(img_emb, dim=-1)\n",
    "\n",
    "        img_proj = img_head(img_emb)\n",
    "        img_proj = Func.normalize(img_proj, dim=-1)\n",
    "\n",
    "        logits = img_proj @ txt_proj.T\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(\"Test accuracy by best validation model:\", correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
